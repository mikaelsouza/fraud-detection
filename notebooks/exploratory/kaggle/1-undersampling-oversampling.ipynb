{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Undersampling and Oversampling\n",
    "\n",
    "In this notebook, I'll explore ways to help with our bad classifier predictions. While our accuracy was pretty high, our precision and recall weren't that good. As previously explained, this behaviour is expected because of our unbalanced dataset.\n",
    "\n",
    "Some ways to help to prevent classifiers to generalise badly is to undersample and oversample our data and I'll explore what these concepts mean and how to use them properly.\n",
    "\n",
    "Undersampling can be described as a way to reduce the imbalance in a dataset by removing data points from the classes that are in higher number in the dataset. Oversampling, meanwhile, is to produce more data points for the class that is in lower quantity in order to balance the dataset.\n",
    "\n",
    "We can get a simplistic look at how it works here: https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis\n",
    "\n",
    "I'll be using Sklearn's implementation of undersampling and oversampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn import over_sampling, under_sampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "import fraudutils as futils\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be loading the same data as before, but now I'll split it into train and test while maintaining its distributuin and I'll apply oversampling and undersampling techniques and compare the results of simple ML algorithms, both in accuracy, precision and recall metrics.\n",
    "\n",
    "After loading our dataset, I will be splitting it into train and test and then apply undersampling and oversampling techniques on the training set. This way we can use the new generated train set to train our algorithms and see how they perform on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = pd.read_csv('../../../data/raw/kaggle/creditcard.csv')\n",
    "X_ = cc_df.drop(['Time', 'Class'], axis=1)\n",
    "y_ = cc_df['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0, stratify=y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be comparing classifiers before and after applying undersampling and oversampling as shown bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X_train, X_test, y_train, y_test, random_state=0, classifier=LogisticRegression):\n",
    "    lrc = classifier(random_state=random_state)\n",
    "    lrc.fit(X_train, y_train)\n",
    "    y_pred = lrc.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Mean accuracy: {}\".format(accuracy))\n",
    "    print(\"Mean precision: {}\".format(precision))\n",
    "    print(\"Mean recall: {}\".format(recall))\n",
    "    \n",
    "    return {'accuracy': accuracy, \n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No sampling applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_scores = {}\n",
    "decision_tree_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression results:\n",
      "Mean accuracy: 0.9991748885221726\n",
      "Mean precision: 0.8493150684931506\n",
      "Mean recall: 0.6326530612244898\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression results:\")\n",
    "logistic_regression_scores['normal'] = classify(X_train, X_test, y_train, y_test, classifier=LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree results:\n",
      "Mean accuracy: 0.9991222218320986\n",
      "Mean precision: 0.75\n",
      "Mean recall: 0.7346938775510204\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision tree results:\")\n",
    "decision_tree_scores['normal'] = classify(X_train, X_test, y_train, y_test, classifier=DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random oversampling applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = over_sampling.RandomOverSampler(random_state=0)\n",
    "X_oversampled, y_oversampled = ros.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression results:\n",
      "Mean accuracy: 0.9780379902391068\n",
      "Mean precision: 0.0649056603773585\n",
      "Mean recall: 0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression results:\")\n",
    "logistic_regression_scores['oversampled'] = classify(X_oversampled, X_test, y_oversampled, y_test, classifier=LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree results:\n",
      "Mean accuracy: 0.9991222218320986\n",
      "Mean precision: 0.75\n",
      "Mean recall: 0.7346938775510204\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision tree results:\")\n",
    "decision_tree_scores['oversampled'] = classify(X_oversampled, X_test, y_oversampled, y_test, classifier=DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random undersampling applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = under_sampling.RandomUnderSampler(random_state=0)\n",
    "X_undersampled, y_undersampled = rus.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression results:\n",
      "Mean accuracy: 0.9702784312348584\n",
      "Mean precision: 0.04918032786885246\n",
      "Mean recall: 0.8877551020408163\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression results:\")\n",
    "logistic_regression_scores['undersampled'] = classify(X_undersampled, X_test, y_undersampled, y_test, classifier=LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree results:\n",
      "Mean accuracy: 0.9086408482848215\n",
      "Mean precision: 0.01611068991660349\n",
      "Mean recall: 0.8673469387755102\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision tree results:\")\n",
    "decision_tree_scores['undersampled'] = classify(X_undersampled, X_test, y_undersampled, y_test, classifier=DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>oversampled</th>\n",
       "      <th>undersampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999175</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>0.970278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.064906</td>\n",
       "      <td>0.049180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.887755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             normal  oversampled  undersampled\n",
       "accuracy   0.999175     0.978038      0.970278\n",
       "precision  0.849315     0.064906      0.049180\n",
       "recall     0.632653     0.877551      0.887755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_df = pd.DataFrame(logistic_regression_scores)\n",
    "logistic_regression_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>oversampled</th>\n",
       "      <th>undersampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999122</td>\n",
       "      <td>0.999122</td>\n",
       "      <td>0.908641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.016111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.867347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             normal  oversampled  undersampled\n",
       "accuracy   0.999122     0.999122      0.908641\n",
       "precision  0.750000     0.750000      0.016111\n",
       "recall     0.734694     0.734694      0.867347"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_df = pd.DataFrame(decision_tree_scores)\n",
    "decision_tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
